{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import correlate, correlation_lags\n",
    "from vr2f.helpers import chkmkdir\n",
    "from vr2f.staticinfo import CONSTANTS, PATHS\n",
    "\n",
    "\n",
    "class LagCalculatorEyetrackingVsEog:\n",
    "  \"\"\"Calculate the lag between eye tracking (ET) and electrooculography (EOG) data for a given subject.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    \"\"\"Initialize constants.\"\"\"\n",
    "    self.constants = CONSTANTS()\n",
    "    self.paths = PATHS()\n",
    "\n",
    "\n",
    "  def get_data(self, sub_id, picks=\"eog\"):\n",
    "      \"\"\"Get EOG data for given subject.\"\"\"\n",
    "      path_in = Path(self.paths.DATA_01_EPO, \"erp\", \"clean\")\n",
    "      fname = Path(path_in, f\"{sub_id}-epo.fif\")\n",
    "      epos = mne.read_epochs(fname, verbose=False).pick(picks)\n",
    "      times = epos.times\n",
    "      info = epos.info\n",
    "\n",
    "      return epos, times, info\n",
    "\n",
    "\n",
    "  def zscore_array(self, arr, axis=0):\n",
    "      \"\"\"Z-score an array.\"\"\"\n",
    "      return (arr - np.nanmean(arr, axis=axis)) / np.nanstd(arr, axis=axis)\n",
    "\n",
    "\n",
    "  def get_et_eog_df(self, et_data_full, sub_id, trial_range=None):\n",
    "    \"\"\"\n",
    "    Extract and process eye tracking (ET) and electrooculography (EOG) data for a given subject.\n",
    "\n",
    "    This function processes ET and EOG data for a specified subject. It computes vertical and\n",
    "    horizontal components for both ET and EOG data, z-scores them, and aligns them in time.\n",
    "    Optionally, it can plot the aligned data. The function returns a list of pandas DataFrames,\n",
    "    each containing aligned and processed ET and EOG data for each trial within the specified trial range.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    et_data_full : pandas.DataFrame\n",
    "        A DataFrame containing the full eye tracking data for all subjects and trials.\n",
    "    sub_id : int or str\n",
    "        The subject identifier for which to extract and process ET and EOG data.\n",
    "    trial_range : range, optional\n",
    "        A range object specifying the trials to process. If None, all trials for the subject are processed.\n",
    "        Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    et_eog_dfs : list of pandas.DataFrame\n",
    "        A list of DataFrames, each containing the processed and aligned ET and EOG data for a trial.\n",
    "        Each DataFrame has columns for times, ET vertical and horizontal components (phi, theta),\n",
    "        andEOG vertical and horizontal components (vert, hor).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The function assumes a specific structure for the input `et_data_full` DataFrame, including\n",
    "    columns for trial numbers and eye tracking metrics (phi, theta).\n",
    "    - EOG data is loaded and processed using predefined picks for EEG and EOG channels.\n",
    "    - The function z-scores the ET and EOG components within each trial.\n",
    "    - If `plot_it` is True, the function generates a plot for each trial, showing both ET and EOG components.\n",
    "    - The function aligns ET and EOG data in time and interpolates EOG data to match ET data timestamps.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> et_data_full = pd.read_csv('eye_tracking_data.csv')\n",
    "    >>> sub_id = 1\n",
    "    >>> et_eog_dfs = get_et_eog_df(et_data_full, sub_id)\n",
    "    >>> print(et_eog_dfs[0].head())\n",
    "\n",
    "    \"\"\"\n",
    "    n_trials_train = self.constants.N_TRIALS_TRAINING\n",
    "\n",
    "    # load eog data\n",
    "    eog_data, eog_times, info = self.get_data(sub_id, picks=(\"eeg\",\"eog\"))\n",
    "\n",
    "    d_fp1 = eog_data.get_data(picks=\"Fp1\")\n",
    "    d_fp2 = eog_data.get_data(picks=\"Fp2\")\n",
    "    d_io1 = eog_data.get_data(picks=\"IO1\")\n",
    "    d_io2 = eog_data.get_data(picks=\"IO2\")\n",
    "    d_lo1 = eog_data.get_data(picks=\"LO1\")\n",
    "    d_lo2 = eog_data.get_data(picks=\"LO2\")\n",
    "\n",
    "    if trial_range is None:\n",
    "      trial_range = range(len(eog_data))\n",
    "\n",
    "    et_eog_dfs= []\n",
    "\n",
    "    for trial_idx in trial_range:\n",
    "      eog_vert = -1 * ((d_fp1 - d_io1) + (d_fp2 - d_io2)) / 2\n",
    "      eog_vert = eog_vert.squeeze()[trial_idx, :]\n",
    "      eog_vert = self.zscore_array(eog_vert, axis=0)\n",
    "\n",
    "      eog_hor = -1 * (d_lo1 - d_lo2)\n",
    "      eog_hor = eog_hor.squeeze()[trial_idx, :]\n",
    "      eog_hor = self.zscore_array(eog_hor, axis=0)\n",
    "\n",
    "      et_sub = et_data_full.copy()\n",
    "      et_sub = et_sub[et_sub[\"trial_num\"] > n_trials_train]\n",
    "      # subtract the number of train trials from the trial number\n",
    "      et_sub.loc[:,\"trial_idx\"] = et_sub.loc[:,\"trial_num\"] - (n_trials_train+1)\n",
    "\n",
    "      et_sub_trial = et_sub[(et_sub[\"trial_idx\"] == trial_idx)]\n",
    "      if et_sub_trial.empty:\n",
    "        print(f\"WARNING: No data found for trial {trial_idx} in {sub_id}. Skipping...\")\n",
    "        continue\n",
    "      et_sub_trial = et_sub_trial.reset_index()\n",
    "      et_times = et_sub_trial[\"times\"]\n",
    "\n",
    "      idx_times = ((et_times >= np.min(eog_times)) &\n",
    "                  (et_times <= np.max(eog_times)))\n",
    "      # make fixed length relative to t0 (assuming sfreq of 120Hz)\n",
    "      n_neg = int(constants.SFREQ_ET * 0.250)\n",
    "      n_pos = int(constants.SFREQ_ET * 0.950)\n",
    "      # make mask:\n",
    "      idx_tzero = et_times.abs().idxmin()\n",
    "      mask = np.zeros(len(et_times), dtype=bool)\n",
    "      mask[(idx_tzero - n_neg):(idx_tzero + n_pos + 1)] = True\n",
    "\n",
    "      et_sub_trial = et_sub_trial[idx_times & mask]\n",
    "      et_times = et_times[idx_times & mask]\n",
    "\n",
    "      et_vert = et_sub_trial[\"phi\"].to_numpy()\n",
    "      et_vert = self.zscore_array(et_vert)\n",
    "      et_hor = et_sub_trial[\"theta\"].to_numpy()\n",
    "      et_hor = self.zscore_array(et_hor)\n",
    "\n",
    "      times_union = np.union1d(eog_times, et_times)\n",
    "\n",
    "      df_et = pd.DataFrame({\"times\": et_times, \"phi\": et_vert, \"theta\": et_hor})\n",
    "      df_et = df_et.set_index(\"times\")\n",
    "\n",
    "      df_eog = pd.DataFrame({\"times\": eog_times, \"vert\": eog_vert, \"hor\": eog_hor})\n",
    "      df_eog = df_eog.set_index(\"times\")\n",
    "      df_eog = df_eog.reindex(times_union).interpolate()\n",
    "      df_all = df_et.merge(df_eog, left_on=\"times\", right_index=True)\n",
    "\n",
    "      et_eog_dfs.append(df_all)\n",
    "\n",
    "    return et_eog_dfs\n",
    "\n",
    "\n",
    "  def calc_xcorrs(self, df_et_eogs):\n",
    "    \"\"\"Calculate cross-correlations and lags between ET and EOG data.\"\"\"\n",
    "    xcorrs = {}\n",
    "    xcorrs[\"vert\"] = []\n",
    "    xcorrs[\"hor\"] = []\n",
    "    lags = {}\n",
    "    lags[\"vert\"] = []\n",
    "    lags[\"hor\"] = []\n",
    "\n",
    "    for df_et_eog in df_et_eogs:\n",
    "      xcorr_v = correlate(df_et_eog[\"phi\"], df_et_eog[\"vert\"])\n",
    "      xcorr_h = correlate(df_et_eog[\"theta\"], df_et_eog[\"hor\"])\n",
    "      lags_v = correlation_lags(len(df_et_eog[\"phi\"]), len(df_et_eog[\"vert\"]))\n",
    "      lags_h = correlation_lags(len(df_et_eog[\"theta\"]), len(df_et_eog[\"hor\"]))\n",
    "\n",
    "      xcorrs[\"vert\"].append(xcorr_v)\n",
    "      xcorrs[\"hor\"].append(xcorr_h)\n",
    "      lags[\"vert\"].append(lags_v)\n",
    "      lags[\"hor\"].append(lags_h)\n",
    "\n",
    "    return xcorrs, lags\n",
    "\n",
    "\n",
    "  def plot_xcorrs(self, xcorrs, lags, sub_id=\"\"):\n",
    "    \"\"\"Plot cross-correlations and lags.\"\"\"\n",
    "    m_v = np.nanmean(np.asarray(np.abs(xcorrs[\"vert\"])), axis=0)\n",
    "    m_h = np.nanmean(np.asarray(xcorrs[\"hor\"]), axis=0)\n",
    "    lags_v = np.nanmean(np.asarray(lags[\"vert\"]), axis=0)\n",
    "    lags_h = np.nanmean(np.asarray(lags[\"hor\"]), axis=0)\n",
    "    sd_v = np.asarray(xcorrs[\"vert\"]).std(axis=0)\n",
    "    sd_h = np.asarray(xcorrs[\"hor\"]).std(axis=0)\n",
    "\n",
    "    max_corr_v = np.argmax(np.abs(m_v))\n",
    "    max_corr_h = np.argmax(np.abs(m_h))\n",
    "\n",
    "    print(f\"#### {sub_id} ####\")\n",
    "    print(f\"Top correlation for vertical: {max_corr_v} at {lags_v[max_corr_v]}\")\n",
    "    print(f\"Top correlation for horizontal: {max_corr_h} at {lags_h[max_corr_h]}\")\n",
    "\n",
    "    lag_v_max = lags_v[max_corr_v] * 1/self.constants.SFREQ_ET\n",
    "    lag_h_max = lags_h[max_corr_h] * 1/self.constants.SFREQ_ET\n",
    "    lag_mean = np.mean([lag_v_max, lag_h_max])\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.fill_between(lags_v, m_v - sd_v, m_v + sd_v, alpha=0.5)\n",
    "    plt.fill_between(lags_h, m_h - sd_h, m_h + sd_h, alpha=0.5)\n",
    "\n",
    "    plt.plot(lags_v, m_v)\n",
    "    plt.plot(lags_h, m_h)\n",
    "    plt.vlines(lag_mean * constants.SFREQ_ET, np.min(m_v), np.max(m_v), colors=\"r\", linestyles=\"--\")\n",
    "    plt.xlabel(\"Lag (samples)\")\n",
    "    plt.ylabel(\"Correlation (a.u.)\")\n",
    "    plt.title(f\"XCorr EOG and ET: {sub_id}\")\n",
    "    plt.legend([\"Vertical\", \"Horizontal\"])\n",
    "    plt.text(lag_mean * constants.SFREQ_ET, 0, f\"mean lag: {(1000 * lag_mean):.1f}ms\", color=\"r\")\n",
    "\n",
    "    # save to file\n",
    "    path_out = Path(self.paths.DATA_ET_PREPROC, \"lags\", \"plots\")\n",
    "    chkmkdir(path_out)\n",
    "    fpath_out = Path(path_out, f\"{sub_id}_xcorr.png\")\n",
    "    plt.savefig(fpath_out)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "  def write_lag_df_csv(self, xcorrs, lags, sub_id):\n",
    "    \"\"\"Write lags to a CSV file.\"\"\"\n",
    "    m_v = np.nanmean(np.asarray(np.abs(xcorrs[\"vert\"])), axis=0)\n",
    "    m_h = np.nanmean(np.asarray(xcorrs[\"hor\"]), axis=0)\n",
    "    lags_v = np.nanmean(np.asarray(lags[\"vert\"]), axis=0)\n",
    "    lags_h = np.nanmean(np.asarray(lags[\"hor\"]), axis=0)\n",
    "\n",
    "    max_corr_v = np.argmax(np.abs(m_v))\n",
    "    max_corr_h = np.argmax(np.abs(m_h))\n",
    "\n",
    "    lag_v_max = lags_v[max_corr_v] * 1/self.constants.SFREQ_ET\n",
    "    lag_h_max = lags_h[max_corr_h] * 1/self.constants.SFREQ_ET\n",
    "    lag_mean = np.mean([lag_v_max, lag_h_max])\n",
    "\n",
    "    # write to DF\n",
    "    df_lag = pd.DataFrame({\"lag_mean\": lag_mean,\n",
    "                          \"lag_vert\": lag_v_max, \"lag_hor\": lag_h_max},\n",
    "                          index=[sub_id])\n",
    "    path_df_lags = Path(self.paths.DATA_ET_PREPROC, \"lags\", \"DF_lags.csv\")\n",
    "    if path_df_lags.exists():\n",
    "      df_old = pd.read_csv(path_df_lags).set_index(\"sub_id\")\n",
    "      if sub_id in df_old.index:\n",
    "        df_old = df_old.drop(index=sub_id)\n",
    "        print(f\"WARNING: overwriting existing entry for {sub_id}.\")\n",
    "      df_lag = pd.concat([df_old, df_lag], axis=0)\n",
    "    df_lag.to_csv(path_df_lags, index=True, index_label=\"sub_id\")\n",
    "\n",
    "\n",
    "  def get_et_vs_eog_lag(self, sub_id, et_data, plot_it=False, write_csv=True):\n",
    "    \"\"\"\n",
    "    Calculate the lag between eye tracking (ET) and electrooculography (EOG) data for a given subject.\n",
    "\n",
    "    This function processes ET and EOG data for a specified subject to find the lag between these two types of data.\n",
    "    It optionally plots the cross-correlations and writes the lag information to a CSV file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sub_id : int or str\n",
    "        The subject identifier for which to calculate the ET and EOG lag.\n",
    "    et_data : pandas.DataFrame\n",
    "        A DataFrame containing the full eye tracking data for all subjects and trials.\n",
    "    plot_it : bool, optional\n",
    "        If True, plots the cross-correlations between ET and EOG data. Default is False.\n",
    "    write_csv : bool, optional\n",
    "        If True, writes the calculated lag information to a CSV file. Default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The mean lag between ET and EOG data, calculated as the average of the maximum\n",
    "        correlation lags for vertical and horizontal components.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function relies on several helper functions to process the data, calculate\n",
    "    cross-correlations, and optionally plot and write results.\n",
    "    - The lag is calculated as the mean of the maximum correlation lags for both\n",
    "    vertical and horizontal components of the ET and EOG data.\n",
    "    - The function assumes that the ET data has been preprocessed and is passed as a DataFrame.\n",
    "    - If `plot_it` is True, the function generates a plot showing the cross-correlations\n",
    "    for both vertical and horizontal components.\n",
    "    - If `write_csv` is True, the function writes the calculated lag information to a CSV file for later reference.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> et_data = pd.read_csv('eye_tracking_data.csv')\n",
    "    >>> sub_id = \"VR2FEM_S23\"\n",
    "    >>> mean_lag = get_et_vs_eog_lag(sub_id, et_data, plot_it=True, write_csv=False)\n",
    "    >>> print(f\"Mean lag: {mean_lag}\")\n",
    "\n",
    "    \"\"\"\n",
    "    df_et_eog = self.get_et_eog_df(et_data, sub_id)\n",
    "    xcorrs, lags = self.calc_xcorrs(df_et_eog)\n",
    "    if plot_it:\n",
    "      self.plot_xcorrs(xcorrs, lags, sub_id)\n",
    "    if write_csv:\n",
    "      self.write_lag_df_csv(xcorrs, lags, sub_id)\n",
    "\n",
    "    m_v = np.nanmean(np.asarray(np.abs(xcorrs[\"vert\"])), axis=0)\n",
    "    m_h = np.nanmean(np.asarray(xcorrs[\"hor\"]), axis=0)\n",
    "    lags_v = np.nanmean(np.asarray(lags[\"vert\"]), axis=0)\n",
    "    lags_h = np.nanmean(np.asarray(lags[\"hor\"]), axis=0)\n",
    "\n",
    "    max_corr_v = np.argmax(np.abs(m_v))\n",
    "    max_corr_h = np.argmax(np.abs(m_h))\n",
    "\n",
    "    lag_v_max = lags_v[max_corr_v] * 1/self.constants.SFREQ_ET\n",
    "    lag_h_max = lags_h[max_corr_h] * 1/self.constants.SFREQ_ET\n",
    "    return np.mean([lag_v_max, lag_h_max])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No data found for trial 487 in VR2FEM_S31. Skipping...\n",
      "#### VR2FEM_S31 ####\n",
      "Top correlation for vertical: 151 at 7.0\n",
      "Top correlation for horizontal: 152 at 8.0\n",
      "WARNING: overwriting existing entry for VR2FEM_S31.\n"
     ]
    }
   ],
   "source": [
    "sub_id = \"VR2FEM_S31\"\n",
    "blink_cond =  \"withblinks\"  # \"preproc\" #\n",
    "paths = PATHS()\n",
    "\n",
    "# load ET data\n",
    "sub_list_str_et = [f.split(\"-\")[0] for f in os.listdir(PATHS().DATA_ET_PREPROC) if blink_cond in f]\n",
    "\n",
    "fname = Path(paths.DATA_ET_PREPROC, f\"{sub_id}-ET-{blink_cond}.csv\")\n",
    "et_data_full = pd.read_csv(fname, sep=\",\")\n",
    "\n",
    "LC = LagCalculatorEyetrackingVsEog()\n",
    "\n",
    "lag = LC.get_et_vs_eog_lag(sub_id, et_data_full, plot_it=True, write_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No data found for trial 487 in VR2FEM_S31. Skipping...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "constants = CONSTANTS()\n",
    "\n",
    "df_et_eog = get_et_eog_df(et_data_full, sub_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcorrs, lags = calc_xcorrs(df_et_eog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: VR2FEM_S31 has different length xcorrs for trial 186.: 299\n",
      "WARNING: VR2FEM_S31 has different length xcorrs for trial 562.: 299\n",
      "WARNING: VR2FEM_S31 has different length xcorrs for trial 568.: 299\n",
      "WARNING: VR2FEM_S31 has different length xcorrs for trial 657.: 299\n"
     ]
    }
   ],
   "source": [
    "for idx, xc in enumerate(xcorrs[\"vert\"]):\n",
    "  if len(xc) != len(xcorrs[\"vert\"][0]):\n",
    "    print(f\"WARNING: {sub_id} has different length xcorrs for trial {idx}.: {len(xc)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vr2fem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
