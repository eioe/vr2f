{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ca320a",
   "metadata": {},
   "source": [
    "Use this notebook to calculate and save saccades and fixations from the eye tracking data. Subsequent scripts which\n",
    "perform the analyses on saccades and fixations load the according files from the data folder. The results come precalculated\n",
    "with the dataset but if you want you can recalculate and overwrite them here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "from tqdm.auto import tqdm\n",
    "from vr2f.eyetracking import et_plot_gaze_saccades, et_utils, ms_toolbox\n",
    "from vr2f.staticinfo import PATHS, CONSTANTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3431d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = PATHS()\n",
    "constants = CONSTANTS()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b060ea7",
   "metadata": {},
   "source": [
    "## Calculate saccades and fixations\n",
    "In the following we use algorithms from the Microsaccade Toolbox (Engbert & Kliegl, 2003) to detect saccades (and \n",
    "fixations) in our data and write out files with this information.  \n",
    "Running these calculations from the notebook can take a while. So I recommend to read in the saved files and skip this \n",
    "step. You can also rerun them once and overwrite the saved files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d459b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECALCULATE_SACC_AND_FIX_DATA = False\n",
    "WRITE_TO_DISK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca080c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sacc_fix_per_sub(args):\n",
    "    df_all, trial_range, sub_id = args\n",
    "    print(f\"Processing {sub_id}\")\n",
    "    sfreq = constants.SFREQ_ET\n",
    "    vfac = constants.ET_SACC_VFAC\n",
    "    mindur = constants.ET_SACC_MINDUR\n",
    "\n",
    "    df_sub = df_all.query(\"sub_id == @sub_id\").copy()\n",
    "    df_gaze_subject = pd.DataFrame()\n",
    "\n",
    "    sacs = pd.DataFrame()\n",
    "    for trial_idx in tqdm(trial_range):\n",
    "        df_st = et_plot_gaze_saccades.get_data_sub_trialnum(df_sub, sub_id, trial_idx)\n",
    "        if df_st.empty:\n",
    "            print(f\"!!! Warning: No data for {sub_id} and trial {trial_idx}. Skipping this trial.\")\n",
    "            continue\n",
    "        data = df_st.loc[:,[\"theta\", \"phi\"]].to_numpy()\n",
    "        sac, rad = ms_toolbox.microsacc(data, srate=sfreq, vfac=vfac, mindur=mindur)\n",
    "        sac[\"trial_num\"] = trial_idx\n",
    "        sacs = pd.concat([sacs, sac], ignore_index=True)\n",
    "        df_st[\"gaze_state\"] = \"fix\"\n",
    "        df_st[\"idx_fix\"] = 0\n",
    "        for i, row in sac.iterrows():\n",
    "            onset = row[\"idx_onset\"]\n",
    "            offset = row[\"idx_offset\"]\n",
    "            df_st.loc[onset:offset+1, [\"gaze_state\"]] = \"sacc\"\n",
    "            df_st.loc[onset:offset+1, [\"idx_sacc\"]] = i\n",
    "            df_st.loc[offset:, \"idx_fix\"] = i+1\n",
    "        df_gaze_subject = pd.concat([df_gaze_subject, df_st], ignore_index=True)\n",
    "    sacs[\"sub_id\"] = sub_id\n",
    "    df_gaze_subject[\"idx_sacc\"] = df_gaze_subject[\"idx_sacc\"].fillna(-99)\n",
    "    df_gaze_subject[\"idx_sacc\"] = df_gaze_subject[\"idx_sacc\"].astype(int)\n",
    "    return (df_gaze_subject, sacs)\n",
    "\n",
    "\n",
    "if RECALCULATE_SACC_AND_FIX_DATA:    \n",
    "    # read in the preprocessed data\n",
    "    pattern = \"withoutblinks-preproc.csv\"\n",
    "\n",
    "    sub_list_str_et = [f for f in os.listdir(paths.DATA_ET_PREPROC) if pattern in f]\n",
    "    sub_list_str_et = [f.split(\"-\")[0] for f in sub_list_str_et]\n",
    "    sub_list_str_et = np.unique(sorted(sub_list_str_et))\n",
    "\n",
    "    data_preproc = []\n",
    "    for sub_id in sorted(sub_list_str_et):\n",
    "        fname = Path(paths.DATA_ET_PREPROC, f\"{sub_id}-ET-{pattern}\")\n",
    "        df_clean = pd.read_csv(fname, sep=\",\")\n",
    "        df_clean[\"sub_id\"] = sub_id\n",
    "        data_preproc.append(df_clean)\n",
    "\n",
    "    df_all = pd.concat(data_preproc, ignore_index=True)\n",
    "\n",
    "    # Choose subjects\n",
    "    sub_id_selection = sub_list_str_et\n",
    "    num_processes = len(sub_id_selection)\n",
    "\n",
    "    # Prepare input\n",
    "    trial_range = range(1, 745) # all trials\n",
    "\n",
    "    args_list = [(df_all, trial_range, sub_id) for sub_id in sub_id_selection]\n",
    "\n",
    "    # Run it on pool\n",
    "    pool = Pool(processes=num_processes)\n",
    "    results = pool.map(get_sacc_fix_per_sub, args_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "    # Combine the gaze DFs for all subjects and write to disk\n",
    "    df_gaze = pd.concat([res[0] for res in results], ignore_index=True)\n",
    "\n",
    "    if WRITE_TO_DISK:\n",
    "        fpath = paths.DATA_ET / \"02_gaze\"\n",
    "        fpath.mkdir(exist_ok=True, parents=True)\n",
    "        df_gaze.to_csv(Path(fpath, \"gaze_all.csv\"), index=False)\n",
    "    \n",
    "    \n",
    "    # We do the same for the saccades DF, but first we add columns with the onset and offset time of the saccade:\n",
    "    saccades = pd.concat([res[1] for res in results], ignore_index=True)\n",
    "    sacc_times = (df_gaze\n",
    "                    .query(\"gaze_state == 'sacc'\")\n",
    "                    .groupby([\"sub_id\", \"trial_num\", \"idx_sacc\"], as_index=False)\n",
    "                    .agg({\"times\": [\"first\", \"last\"]})\n",
    "                    .reset_index()\n",
    "                )\n",
    "    sacc_times.columns = list(map(\"\".join, sacc_times.columns))\n",
    "    sacc_times.columns = (sacc_times.rename(columns= {\"timesfirst\": \"times_onset\", \n",
    "                                            \"timeslast\": \"times_offset\"})\n",
    "                                    .columns\n",
    "                        )\n",
    "\n",
    "    saccades = (saccades\n",
    "                .assign(idx_sacc = lambda x:\n",
    "                            (x.groupby([\"sub_id\", \"trial_num\"])\n",
    "                            .cumcount()\n",
    "                            )\n",
    "                        )\n",
    "                .merge(sacc_times.drop([\"index\"], axis=1),\n",
    "                        on=[\"sub_id\", \"trial_num\", \"idx_sacc\"])\n",
    "            )\n",
    "\n",
    "    saccades[\"amp_tot\"] = np.sqrt(saccades[\"amp_x\"]**2 + saccades[\"amp_y\"]**2)\n",
    "    saccades[\"angle\"] = (saccades\n",
    "                        .apply(lambda x: et_utils.angle_from_spherical(x.vec_x, x.vec_y), axis=1)\n",
    "    )\n",
    "\n",
    "    if WRITE_TO_DISK:\n",
    "        fpath = paths.DATA_ET / \"02_gaze\"\n",
    "        fpath.mkdir(exist_ok=True, parents=True)\n",
    "        saccades.to_csv(Path(fpath, \"saccades_all.csv\"), index=False)\n",
    "\n",
    "\n",
    "    fixations = (df_gaze\n",
    "        .query(\"gaze_state == 'fix'\")\n",
    "        .groupby([\"sub_id\", \"trial_num\", \"gaze_state\", \"idx_fix\"], as_index=False)\n",
    "        .agg({\"times\": [\"first\", \"last\"],\n",
    "                \"theta\": [\"mean\", \"min\", \"max\"],\n",
    "                \"phi\": [\"mean\", \"min\", \"max\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    fixations.columns = list(map(\"\".join, fixations.columns))\n",
    "    fixations.columns = (fixations.rename(columns={\"timesfirst\": \"times_onset\", \"timeslast\":\n",
    "                                                \"times_offset\", \"thetamean\": \"center_theta\",\n",
    "                                                \"thetamin\": \"min_theta\", \"thetamax\": \"max_theta\",\n",
    "                                                \"phimean\": \"center_phi\", \"phimin\": \"min_phi\",\n",
    "                                                \"phimax\": \"max_phi\"})\n",
    "                                .columns\n",
    "                        )\n",
    "    fixations[\"duration\"] = fixations[\"times_offset\"] - fixations[\"times_onset\"]\n",
    "    fixations[\"spread_theta\"] = fixations[\"max_theta\"] - fixations[\"min_theta\"]\n",
    "    fixations[\"spread_phi\"] = fixations[\"max_phi\"] - fixations[\"min_phi\"]\n",
    "\n",
    "    if WRITE_TO_DISK:\n",
    "        fpath = paths.DATA_ET / \"02_gaze\"\n",
    "        fpath.mkdir(exist_ok=True, parents=True)\n",
    "        fixations.to_csv(Path(fpath, \"fixations_all.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vr2fem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
