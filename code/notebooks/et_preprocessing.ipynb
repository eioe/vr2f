{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eye tracking: preprocessing\n",
    "\n",
    "This script imports the raw eye tracking (ET) data from the `Subjects` folder\n",
    "and runs a few preprocessing steps on them:\n",
    "\n",
    "1. Transform the gaze vectors into spherical coordinates (`theta`: horizontal \n",
    "gaze angle, `phi`: vertical)  \n",
    "2. Calculate the time relative to the stimulus onset event.  \n",
    "3. Correct for the temporal offset between the actual eye movement and the time \n",
    "the eye tracker provides the accordinmg sample (using cross-correlation with the \n",
    "instantaneous EOG signal)\n",
    "4. Subtract the mean baseline in a window of `200 ms` before stimulus onset from\n",
    "each trial (separately for `theta` and `phi`).\n",
    "5. Optional (see parameter `blinks_interpolate` at the beginning of the notebook): identify blinks in the data and replace them via linear interpolation. \n",
    "6. Save the files as pandas data frames.  \n",
    "  \n",
    "⚠️ We only have ET data for a subset of the participants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from vr2f.staticinfo import COLORS, PATHS\n",
    "from vr2f.eyetracking import lag_calculator_et_vs_eog, et_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = PATHS()\n",
    "colors = COLORS()\n",
    "\n",
    "blinks_interpolate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing VR2FEM_S01...\n",
      "WARNING: overwriting existing entry for VR2FEM_S01.\n",
      "    Correcting for lag of 0.058333333333333334ms for VR2FEM_S01.\n",
      "    VR2FEM_S01: 744 trials\n",
      "Processing VR2FEM_S02...\n",
      "    Correcting for lag of 0.058333333333333334ms for VR2FEM_S02.\n",
      "    VR2FEM_S02: 744 trials\n",
      "Processing VR2FEM_S03...\n",
      "Skipping VR2FEM_S03 because there are no eye tracking files.\n",
      "    Skipping VR2FEM_S03.\n",
      "Processing VR2FEM_S04...\n",
      "    No markerlog for VR2FEM_S04\n",
      "    Skipping VR2FEM_S04.\n",
      "Processing VR2FEM_S05...\n",
      "    Correcting for lag of 0.058333333333333334ms for VR2FEM_S05.\n",
      "    VR2FEM_S05: 744 trials\n",
      "Processing VR2FEM_S06...\n",
      "    Skipping VR2FEM_S06 because there is no eye tracking data.\n",
      "Processing VR2FEM_S07...\n",
      "    Correcting for lag of 0.0625ms for VR2FEM_S07.\n",
      "    VR2FEM_S07: 744 trials\n",
      "Processing VR2FEM_S08...\n",
      "    Correcting for lag of 0.0625ms for VR2FEM_S08.\n",
      "    VR2FEM_S08: 744 trials\n",
      "Processing VR2FEM_S10...\n",
      "WARNING: overwriting existing entry for VR2FEM_S10.\n",
      "    Correcting for lag of 0.058333333333333334ms for VR2FEM_S10.\n",
      "    VR2FEM_S10: 744 trials\n",
      "Processing VR2FEM_S11...\n",
      "    Correcting for lag of 0.06666666666666667ms for VR2FEM_S11.\n",
      "    VR2FEM_S11: 744 trials\n",
      "Processing VR2FEM_S12...\n",
      "    Correcting for lag of 0.0625ms for VR2FEM_S12.\n",
      "    VR2FEM_S12: 744 trials\n",
      "Processing VR2FEM_S13...\n",
      "    Correcting for lag of 0.0625ms for VR2FEM_S13.\n",
      "    VR2FEM_S13: 744 trials\n",
      "Processing VR2FEM_S14...\n",
      "    Skipping VR2FEM_S14 because there is no eye tracking data.\n",
      "Processing VR2FEM_S15...\n",
      "    Correcting for lag of 0.05416666666666667ms for VR2FEM_S15.\n",
      "    VR2FEM_S15: 744 trials\n",
      "Processing VR2FEM_S16...\n",
      "    Correcting for lag of 0.058333333333333334ms for VR2FEM_S16.\n",
      "    VR2FEM_S16: 744 trials\n",
      "Processing VR2FEM_S17...\n",
      "    Skipping VR2FEM_S17 because there is no eye tracking data.\n",
      "Processing VR2FEM_S18...\n",
      "    Skipping VR2FEM_S18 because there is no eye tracking data.\n",
      "Processing VR2FEM_S19...\n",
      "    Correcting for lag of 0.0625ms for VR2FEM_S19.\n",
      "    VR2FEM_S19: 744 trials\n",
      "Processing VR2FEM_S20...\n",
      "    Skipping VR2FEM_S20 because there is no eye tracking data.\n",
      "Processing VR2FEM_S21...\n",
      "    Correcting for lag of 0.0625ms for VR2FEM_S21.\n",
      "    VR2FEM_S21: 744 trials\n",
      "Processing VR2FEM_S22...\n",
      "    Skipping VR2FEM_S22 because there is no eye tracking data.\n",
      "Processing VR2FEM_S23...\n",
      "    Skipping VR2FEM_S23 because there is no eye tracking data.\n",
      "Processing VR2FEM_S24...\n",
      "    Correcting for lag of 0.0625ms for VR2FEM_S24.\n",
      "    VR2FEM_S24: 744 trials\n",
      "Processing VR2FEM_S25...\n",
      "WARNING: overwriting existing entry for VR2FEM_S25.\n",
      "    Correcting for lag of 0.058333333333333334ms for VR2FEM_S25.\n",
      "    VR2FEM_S25: 744 trials\n",
      "Processing VR2FEM_S26...\n",
      "    Skipping VR2FEM_S26 because there is no eye tracking data.\n",
      "Processing VR2FEM_S27...\n",
      "    Skipping VR2FEM_S27 because there is no eye tracking data.\n",
      "Processing VR2FEM_S28...\n",
      "    Skipping VR2FEM_S28 because there is no eye tracking data.\n",
      "Processing VR2FEM_S29...\n",
      "    Skipping VR2FEM_S29 because there is no eye tracking data.\n",
      "Processing VR2FEM_S30...\n",
      "Skipping VR2FEM_S30 because there are no eye tracking files.\n",
      "    Skipping VR2FEM_S30.\n",
      "Processing VR2FEM_S31...\n",
      "WARNING: No data found for trial 487 in VR2FEM_S31. Skipping...\n",
      "WARNING: overwriting existing entry for VR2FEM_S31.\n",
      "    Correcting for lag of 0.0625ms for VR2FEM_S31.\n",
      "    VR2FEM_S31: 743 trials\n",
      "Processing VR2FEM_S32...\n",
      "    Skipping VR2FEM_S32 because there is no eye tracking data.\n",
      "Processing VR2FEM_S33...\n",
      "    Skipping VR2FEM_S33 because there is no eye tracking data.\n",
      "Processing VR2FEM_S34...\n",
      "    Skipping VR2FEM_S34 because there is no eye tracking data.\n",
      "\n",
      "N of subjects with valid ET data: 16.\n"
     ]
    }
   ],
   "source": [
    "sub_list_str = os.listdir(paths.DATA_SUBJECTS)\n",
    "sub_list_str = sorted(sub_list_str)\n",
    "n_valid_subs = 0\n",
    "\n",
    "for sub_id in sub_list_str:\n",
    "    print(f\"Processing {sub_id}...\")\n",
    "\n",
    "    markerlog_stimonsets = et_preprocessing.get_stimonset_df(sub_id)\n",
    "    if markerlog_stimonsets is None:\n",
    "        print(f\"    Skipping {sub_id}.\")\n",
    "        continue\n",
    "    markerlog_stimonsets_np = markerlog_stimonsets[\"timestamp_corrected\"].to_numpy()\n",
    "\n",
    "\n",
    "    et_files, path_et_files = et_preprocessing.get_et_rawfiles(sub_id)\n",
    "    if et_files is None:\n",
    "        print(f\"    Skipping {sub_id}.\")\n",
    "        continue\n",
    "\n",
    "    df_all = pd.DataFrame()\n",
    "    for f in et_files:\n",
    "        t_num = int(f.split(\".csv\")[0][-3:])\n",
    "        fname = Path(path_et_files, f)\n",
    "        df = pd.read_csv(fname, sep=\",\")\n",
    "\n",
    "        df = df.reset_index(drop=False)\n",
    "\n",
    "        # skip this file if it is empty apart from the header\n",
    "        if df.shape[0] == 0:\n",
    "            continue\n",
    "        # add 3 columns theta, phi, r to df\n",
    "        df[[\"theta\", \"phi\", \"r\"]] = et_preprocessing.cart2sph_custom(\n",
    "            df[\"direction_x_local\"], df[\"direction_y_local\"], df[\"direction_z_local\"]\n",
    "        )\n",
    "\n",
    "        # calculate relative time to stimulus onset:\n",
    "        times = df[\"time\"] - markerlog_stimonsets_np[t_num - 1]\n",
    "        # find the index of the stimulus onset\n",
    "        idx_stimonset = np.argmin(np.abs(times))\n",
    "\n",
    "        df[\"times\"] = (df[\"timestamp_lsl\"] - df.loc[idx_stimonset, \"timestamp_lsl\"]) \n",
    "\n",
    "        # crop to [-0.5; 1.5]s window; assuming a stable srate of 120Hz\n",
    "        srate = 120\n",
    "        df = df.iloc[np.max([idx_stimonset - int(0.5 * srate), 0]) : idx_stimonset + int(1.5 * srate) + 1, :]\n",
    "\n",
    "        # add info about the trial\n",
    "        df[\"trial_num\"] = t_num\n",
    "        df[\"marker\"] = markerlog_stimonsets[\"annotation\"].iloc[t_num - 1]\n",
    "        # split marker on whitespace and keep only last part\n",
    "        df[\"marker\"] = df[\"marker\"].str.split().str[-1]\n",
    "        # marker is a 3digit int; split it into its single digits and put each digit into a separate column\n",
    "        df[\"viewcond\"] = df[\"marker\"].str[0].astype(int)\n",
    "        df[\"avatar_id\"] = df[\"marker\"].str[1].astype(int)\n",
    "        df[\"emotion\"] = df[\"marker\"].str[2].astype(int)\n",
    "        df[\"emotion\"] = df[\"emotion\"].map(cond_dict[\"emotion\"])\n",
    "        df[\"avatar_id\"] = df[\"avatar_id\"].map(cond_dict[\"avatar_id\"])\n",
    "        df[\"viewcond\"] = df[\"viewcond\"].map(cond_dict[\"viewcond\"])\n",
    "\n",
    "        df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "\n",
    "    if df.shape[0] == 0:\n",
    "        print(f\"    Skipping {sub_id} because there is no eye tracking data.\")\n",
    "        continue\n",
    "\n",
    "    # calculate a baseline for each trial\n",
    "    baselines = (\n",
    "        df_all.query(\"times < 0 & times > -0.2\").loc[:, [\"theta\", \"phi\", \"trial_num\"]].groupby([\"trial_num\"]).mean()\n",
    "    )\n",
    "\n",
    "    # subtract the baseline from each trial\n",
    "    df_all = df_all.merge(baselines, on=\"trial_num\", suffixes=(\"\", \"_baseline\"))\n",
    "    df_all[\"theta\"] = df_all[\"theta\"] - df_all[\"theta_baseline\"]\n",
    "    df_all[\"phi\"] = df_all[\"phi\"] - df_all[\"phi_baseline\"]\n",
    "\n",
    "    # adaptively correct for the lag between ET and EOG\n",
    "    lag_calculator = lag_calculator_et_vs_eog.LagCalculatorEyetrackingVsEog()\n",
    "    lag = lag_calculator.get_et_vs_eog_lag(sub_id, df_all, plot_it=False, write_csv=True)\n",
    "    df_all[\"times\"] = df_all[\"times\"] - lag\n",
    "    print(f\"    Correcting for lag of {lag}ms for {sub_id}.\")\n",
    "\n",
    "    if blinks_interpolate:\n",
    "        df_all = df_all.groupby([\"trial_num\"]).apply(et_preprocessing.interpolate_blinks)\n",
    "\n",
    "    # save to csv\n",
    "    path_out = Path(paths.DATA_ET_PREPROC)\n",
    "    if blinks_interpolate:\n",
    "        fname = Path(path_out, f\"{sub_id}-ET-withoutblinks.csv\")\n",
    "    else:\n",
    "        fname = Path(path_out, f\"{sub_id}-ET-withblinks.csv\")\n",
    "    df_all.to_csv(fname, sep=\",\", index=False)\n",
    "\n",
    "    n_trials = df_all[\"trial_num\"].nunique()\n",
    "    print(f\"    {sub_id}: {n_trials} trials\")\n",
    "    n_valid_subs += 1\n",
    "    \n",
    "\n",
    "print(f\"\\nN of subjects with valid ET data: {n_valid_subs}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vr2fem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
